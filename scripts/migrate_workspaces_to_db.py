#!/usr/bin/env python
"""
åŽ†å²workspaceè¿ç§»è„šæœ¬

åŠŸèƒ½ï¼š
1. æ‰«æworkspaces/ç›®å½•ä¸‹çš„æ‰€æœ‰ä¼šè¯
2. è§£æžä¼šè¯å…ƒæ•°æ®ï¼ˆhistory.json, decomposition.json, final_session_data.json, report.htmlï¼‰
3. å¯¼å…¥åˆ°æ•°æ®åº“ï¼Œé»˜è®¤åˆ†é…ç»™user_id=1
4. æ”¯æŒå¢žé‡è¿ç§»ï¼ˆè·³è¿‡å·²å­˜åœ¨çš„ä¼šè¯ï¼‰
5. ç”Ÿæˆè¯¦ç»†çš„è¿ç§»æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/migrate_workspaces_to_db.py --user-id 1 --dry-run
    python scripts/migrate_workspaces_to_db.py --user-id 1
"""

import sys
import os
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT))

from src.models import db, User
from src.repositories import SessionRepository
from src.utils.path_manager import get_workspace_dir
from src.utils.logger import logger


class WorkspaceMigrator:
    """Workspaceè¿ç§»å™¨"""
    
    def __init__(self, target_user_id: int, dry_run: bool = False):
        self.target_user_id = target_user_id
        self.dry_run = dry_run
        self.stats = {
            'total': 0,
            'migrated': 0,
            'skipped': 0,
            'failed': 0,
            'errors': []
        }
    
    def parse_workspace(self, workspace_path: Path) -> Optional[Dict]:
        """
        è§£æžworkspaceç›®å½•ï¼Œæå–å…ƒæ•°æ®
        
        Returns:
            dict: åŒ…å«session_id, issue, backend, model, config, historyç­‰å­—æ®µ
            None: è§£æžå¤±è´¥
        """
        session_id = workspace_path.name
        metadata = {
            'session_id': session_id,
            'issue': 'æœªçŸ¥è®®é¢˜',
            'backend': 'deepseek',  # é»˜è®¤å€¼
            'model': 'deepseek-chat',  # é»˜è®¤å€¼
            'config': {},
            'status': 'completed',  # åŽ†å²ä¼šè¯é»˜è®¤ä¸ºå·²å®Œæˆ
            'history': None,
            'decomposition': None,
            'final_session_data': None,
            'search_references': None,
            'report_html': None,
            'report_json': None,
            'created_at': None,
            'completed_at': None
        }
        
        try:
            # 1. å°è¯•ä»Žfinal_session_data.jsonèŽ·å–å®Œæ•´ä¿¡æ¯
            final_data_path = workspace_path / 'final_session_data.json'
            if final_data_path.exists():
                with open(final_data_path, 'r', encoding='utf-8') as f:
                    final_data = json.load(f)
                    metadata['issue'] = final_data.get('issue', metadata['issue'])
                    metadata['final_session_data'] = final_data
                    
                    # æå–history
                    if 'history' in final_data:
                        metadata['history'] = final_data['history']
                    
                    # æå–decomposition
                    if 'decomposition' in final_data:
                        metadata['decomposition'] = final_data['decomposition']
            
            # 2. å¦‚æžœæ²¡æœ‰final_session_dataï¼Œå°è¯•å•ç‹¬åŠ è½½æ–‡ä»¶
            if not metadata['history']:
                history_path = workspace_path / 'history.json'
                if history_path.exists():
                    with open(history_path, 'r', encoding='utf-8') as f:
                        metadata['history'] = json.load(f)
            
            if not metadata['decomposition']:
                decomp_path = workspace_path / 'decomposition.json'
                if decomp_path.exists():
                    with open(decomp_path, 'r', encoding='utf-8') as f:
                        decomp_data = json.load(f)
                        metadata['decomposition'] = decomp_data
                        # å¦‚æžœissueè¿˜æ˜¯é»˜è®¤å€¼ï¼Œä»Ždecompositionæå–
                        if metadata['issue'] == 'æœªçŸ¥è®®é¢˜':
                            metadata['issue'] = decomp_data.get('core_goal', metadata['issue'])
            
            # 3. åŠ è½½report.html
            report_path = workspace_path / 'report.html'
            if report_path.exists():
                with open(report_path, 'r', encoding='utf-8') as f:
                    metadata['report_html'] = f.read()
            
            # 4. å°è¯•ä»Žorchestration_result.jsonèŽ·å–ä¿¡æ¯ï¼ˆè®®äº‹ç¼–æŽ’å®˜æ¨¡å¼ï¼‰
            orch_path = workspace_path / 'orchestration_result.json'
            if orch_path.exists():
                with open(orch_path, 'r', encoding='utf-8') as f:
                    orch_data = json.load(f)
                    metadata['issue'] = orch_data.get('user_requirement', metadata['issue'])
                    # å¯ä»¥å°†æ•´ä¸ªorchestration_resultå­˜å‚¨ä¸ºfinal_session_dataçš„ä¸€éƒ¨åˆ†
                    if not metadata['final_session_data']:
                        metadata['final_session_data'] = orch_data
            
            # 5. å°è¯•æŽ¨æ–­backendå’Œmodelï¼ˆä»Žconfigæˆ–historyä¸­æå–ï¼‰
            if metadata['history'] and isinstance(metadata['history'], list):
                # æ£€æŸ¥ç¬¬ä¸€è½®çš„é…ç½®
                for round_data in metadata['history']:
                    if isinstance(round_data, dict) and 'config' in round_data:
                        config = round_data['config']
                        metadata['backend'] = config.get('backend', metadata['backend'])
                        metadata['model'] = config.get('model', metadata['model'])
                        break
            
            # 6. ä»Žsession_idæå–åˆ›å»ºæ—¶é—´ï¼ˆæ ¼å¼ï¼š20260116_123456_uuidï¼‰
            parts = session_id.split('_')
            if len(parts) >= 2 and parts[0].isdigit() and len(parts[0]) == 8:
                try:
                    date_str = parts[0]
                    time_str = parts[1] if len(parts) > 1 and parts[1].isdigit() else '000000'
                    dt_str = f"{date_str}_{time_str}"
                    metadata['created_at'] = datetime.strptime(dt_str, '%Y%m%d_%H%M%S')
                    # åŽ†å²ä¼šè¯å‡è®¾åˆ›å»ºåŽç«‹å³å®Œæˆ
                    metadata['completed_at'] = metadata['created_at']
                except:
                    pass
            
            # 7. æž„å»ºconfigå­—æ®µï¼ˆç”¨äºŽå­˜å‚¨é…ç½®ä¿¡æ¯ï¼‰
            metadata['config'] = {
                'backend': metadata['backend'],
                'model': metadata['model'],
                'migrated': True,
                'migration_date': datetime.now().isoformat()
            }
            
            return metadata
        
        except Exception as e:
            logger.error(f"[Migrator] è§£æžworkspaceå¤±è´¥ {session_id}: {e}")
            self.stats['errors'].append({
                'session_id': session_id,
                'error': str(e)
            })
            return None
    
    def migrate_workspace(self, metadata: Dict) -> bool:
        """
        å°†å•ä¸ªworkspaceè¿ç§»åˆ°æ•°æ®åº“
        
        Returns:
            bool: æˆåŠŸè¿”å›žTrue
        """
        session_id = metadata['session_id']
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = SessionRepository.get_session_by_id(session_id)
            if existing:
                logger.info(f"[Migrator] ä¼šè¯å·²å­˜åœ¨ï¼Œè·³è¿‡: {session_id}")
                self.stats['skipped'] += 1
                return False
            
            if self.dry_run:
                logger.info(f"[Migrator] [DRY RUN] å°†è¿ç§»: {session_id} -> ç”¨æˆ·{self.target_user_id}")
                self.stats['migrated'] += 1
                return True
            
            # åˆ›å»ºä¼šè¯è®°å½•
            session = SessionRepository.create_session(
                user_id=self.target_user_id,
                session_id=session_id,
                issue=metadata['issue'],
                config=metadata['config']
            )
            
            if not session:
                raise Exception("åˆ›å»ºä¼šè¯å¤±è´¥")
            
            # è®¾ç½®backendå’Œmodel
            session.backend = metadata['backend']
            session.model = metadata['model']
            session.status = metadata['status']
            
            # è®¾ç½®åˆ›å»ºå’Œå®Œæˆæ—¶é—´
            if metadata.get('created_at'):
                session.created_at = metadata['created_at']
            if metadata.get('completed_at'):
                session.completed_at = metadata['completed_at']
            
            db.session.commit()
            
            # æ›´æ–°å„é¡¹æ•°æ®
            if metadata.get('history'):
                SessionRepository.update_history(session_id, metadata['history'])
            
            if metadata.get('decomposition'):
                SessionRepository.update_decomposition(session_id, metadata['decomposition'])
            
            if metadata.get('final_session_data'):
                SessionRepository.update_final_session_data(session_id, metadata['final_session_data'])
            
            if metadata.get('search_references'):
                SessionRepository.update_search_references(session_id, metadata['search_references'])
            
            if metadata.get('report_html'):
                # åªæ›´æ–°report_htmlï¼Œä¸æ”¹å˜çŠ¶æ€ï¼ˆå› ä¸ºå·²ç»æ˜¯completedï¼‰
                session_db = SessionRepository.get_session_by_id(session_id)
                if session_db:
                    session_db.report_html = metadata['report_html']
                    db.session.commit()
            
            logger.info(f"[Migrator] âœ… è¿ç§»æˆåŠŸ: {session_id} -> ç”¨æˆ·{self.target_user_id}")
            self.stats['migrated'] += 1
            return True
        
        except Exception as e:
            logger.error(f"[Migrator] âŒ è¿ç§»å¤±è´¥ {session_id}: {e}")
            self.stats['failed'] += 1
            self.stats['errors'].append({
                'session_id': session_id,
                'error': str(e)
            })
            return False
    
    def scan_and_migrate(self) -> Dict:
        """
        æ‰«æworkspacesç›®å½•å¹¶æ‰§è¡Œè¿ç§»
        
        Returns:
            dict: è¿ç§»ç»Ÿè®¡ä¿¡æ¯
        """
        workspace_root = get_workspace_dir()
        
        if not workspace_root.exists():
            logger.warning(f"[Migrator] Workspaceç›®å½•ä¸å­˜åœ¨: {workspace_root}")
            return self.stats
        
        logger.info(f"[Migrator] å¼€å§‹æ‰«æ: {workspace_root}")
        logger.info(f"[Migrator] ç›®æ ‡ç”¨æˆ·: {self.target_user_id}")
        logger.info(f"[Migrator] æ¨¡å¼: {'DRY RUN (ä¸å®žé™…å†™å…¥)' if self.dry_run else 'å®žé™…è¿ç§»'}")
        
        # æ‰«ææ‰€æœ‰å­ç›®å½•
        workspaces = [d for d in workspace_root.iterdir() if d.is_dir()]
        self.stats['total'] = len(workspaces)
        
        logger.info(f"[Migrator] å‘çŽ° {self.stats['total']} ä¸ªworkspace")
        
        for workspace_path in workspaces:
            session_id = workspace_path.name
            logger.info(f"[Migrator] å¤„ç†: {session_id}")
            
            # è§£æžmetadata
            metadata = self.parse_workspace(workspace_path)
            if not metadata:
                self.stats['failed'] += 1
                continue
            
            # æ‰§è¡Œè¿ç§»
            self.migrate_workspace(metadata)
        
        return self.stats
    
    def print_report(self):
        """æ‰“å°è¿ç§»æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ðŸ“Š è¿ç§»æŠ¥å‘Š")
        print("="*60)
        print(f"æ€»è®¡: {self.stats['total']}")
        print(f"âœ… æˆåŠŸè¿ç§»: {self.stats['migrated']}")
        print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {self.stats['skipped']}")
        print(f"âŒ å¤±è´¥: {self.stats['failed']}")
        
        if self.stats['errors']:
            print(f"\né”™è¯¯è¯¦æƒ…:")
            for error in self.stats['errors'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"  - {error['session_id']}: {error['error']}")
            if len(self.stats['errors']) > 10:
                print(f"  ... è¿˜æœ‰ {len(self.stats['errors']) - 10} ä¸ªé”™è¯¯")
        
        print("="*60)
        
        if self.dry_run:
            print("\nðŸ’¡ è¿™æ˜¯DRY RUNæ¨¡å¼ï¼Œæ²¡æœ‰å®žé™…å†™å…¥æ•°æ®åº“")
            print("   ç§»é™¤ --dry-run å‚æ•°ä»¥æ‰§è¡Œå®žé™…è¿ç§»")


def main():
    parser = argparse.ArgumentParser(
        description='è¿ç§»åŽ†å²workspaceåˆ°æ•°æ®åº“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # é¢„è§ˆè¿ç§»ï¼ˆä¸å®žé™…å†™å…¥ï¼‰
  python scripts/migrate_workspaces_to_db.py --user-id 1 --dry-run
  
  # æ‰§è¡Œè¿ç§»åˆ°ç”¨æˆ·1
  python scripts/migrate_workspaces_to_db.py --user-id 1
  
  # æ‰§è¡Œè¿ç§»åˆ°ç”¨æˆ·2
  python scripts/migrate_workspaces_to_db.py --user-id 2
        """
    )
    
    parser.add_argument(
        '--user-id',
        type=int,
        required=True,
        help='ç›®æ ‡ç”¨æˆ·IDï¼ˆåŽ†å²ä¼šè¯å°†åˆ†é…ç»™æ­¤ç”¨æˆ·ï¼‰'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®žé™…å†™å…¥æ•°æ®åº“ï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–Flaskåº”ç”¨ä¸Šä¸‹æ–‡
    from src.web.app import app
    
    with app.app_context():
        # éªŒè¯ç”¨æˆ·æ˜¯å¦å­˜åœ¨
        user = User.query.get(args.user_id)
        if not user:
            print(f"âŒ é”™è¯¯: ç”¨æˆ·ID {args.user_id} ä¸å­˜åœ¨")
            print(f"   è¯·å…ˆåˆ›å»ºç”¨æˆ·æˆ–ä½¿ç”¨å·²å­˜åœ¨çš„ç”¨æˆ·ID")
            sys.exit(1)
        
        print(f"âœ… ç›®æ ‡ç”¨æˆ·: {user.username} (ID: {user.id})")
        
        # æ‰§è¡Œè¿ç§»
        migrator = WorkspaceMigrator(
            target_user_id=args.user_id,
            dry_run=args.dry_run
        )
        
        stats = migrator.scan_and_migrate()
        migrator.print_report()
        
        # è¿”å›žçŠ¶æ€ç 
        if stats['failed'] > 0:
            sys.exit(1)
        sys.exit(0)


if __name__ == '__main__':
    main()
