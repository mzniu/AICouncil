from langchain_core.prompts import PromptTemplate
from src.agents.langchain_llm import AdapterLLM, ModelConfig
from src.agents import schemas, model_adapter
from src.utils import logger, search_utils
from pydantic import ValidationError
import json
import requests
import os
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import uuid
import traceback
from datetime import datetime

def send_web_event(event_type: str, **kwargs):
    """å‘é€äº‹ä»¶åˆ° Web ç›‘æ§é¢æ¿ã€‚"""
    try:
        url = "http://127.0.0.1:5000/api/update"
        payload = {"type": event_type, **kwargs}
        requests.post(url, json=payload, timeout=1)
    except Exception:
        pass

def clean_json_string(s: str) -> str:
    """æ¸…ç†å­—ç¬¦ä¸²ä¸­çš„ Markdown JSON æ ‡ç­¾ï¼Œå¹¶å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡ã€‚"""
    if not s:
        return ""
    s = s.strip()
    
    # å¯»æ‰¾ç¬¬ä¸€ä¸ª {
    start = s.find('{')
    if start == -1:
        # å°è¯•å¯»æ‰¾æ•°ç»„ [
        start = s.find('[')
        if start == -1:
            return s
            
    # ä½¿ç”¨æ‹¬å·åŒ¹é…å¯»æ‰¾å¯¹åº”çš„ç»“æŸä½ç½®
    brace_count = 0
    in_string = False
    escape = False
    
    for i in range(start, len(s)):
        char = s[i]
        
        if char == '"' and not escape:
            in_string = not in_string
            
        if not in_string:
            if char == '{' or char == '[':
                brace_count += 1
            elif char == '}' or char == ']':
                brace_count -= 1
                if brace_count == 0:
                    return s[start:i+1]
        
        if char == '\\':
            escape = not escape
        else:
            escape = False
            
    # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ‹¬å·ï¼Œå›é€€åˆ°åŸæ¥çš„é€»è¾‘
    end = s.rfind('}')
    if end == -1:
        end = s.rfind(']')
        
    if start != -1 and end != -1 and end > start:
        return s[start:end+1]
    
    return s.strip()

def stream_agent_output(chain, prompt_vars, agent_name, role_type, event_type="agent_action"):
    """æµå¼æ‰§è¡Œ Agent å¹¶å®æ—¶å‘é€åˆ° Webã€‚æ”¯æŒè”ç½‘æœç´¢ã€‚
    è¿”å›: (full_content, search_results)
    """
    full_content = ""
    search_results = ""
    chunk_id = str(uuid.uuid4())
    
    # å…ˆå‘é€ä¸€ä¸ªç©ºå ä½ç¬¦
    if event_type == "agent_action":
        send_web_event(event_type, agent_name=agent_name, role_type=role_type, content="", chunk_id=chunk_id)
    
    # ç¬¬ä¸€è½®æ‰§è¡Œ
    for chunk in chain.stream(prompt_vars):
        # å¤„ç†å¯èƒ½å­˜åœ¨çš„æ¨ç†å†…å®¹ (DeepSeek R1)
        reasoning = ""
        content = ""
        
        if hasattr(chunk, "generation_info") and chunk.generation_info:
            reasoning = chunk.generation_info.get("reasoning", "")
        
        if hasattr(chunk, "text"):
            content = chunk.text
        else:
            content = str(chunk)

        if reasoning:
            send_web_event(event_type, agent_name=agent_name, role_type=role_type, reasoning=reasoning, chunk_id=chunk_id)
        
        if content:
            full_content += content
            # logger.debug(f"[{agent_name}] Accumulated content length: {len(full_content)}")
            if event_type == "final_report":
                # å®æ—¶æ¸…ç†å¹¶å‘é€åˆ° Webï¼Œé¿å…æ˜¾ç¤º ```html æ ‡ç­¾
                display_html = full_content.strip()
                if display_html.startswith("```html"):
                    display_html = display_html[7:]
                elif display_html.startswith("```"):
                    display_html = display_html[3:]
                if display_html.endswith("```"):
                    display_html = display_html[:-3]
                send_web_event(event_type, content=display_html.strip())
            else:
                send_web_event(event_type, agent_name=agent_name, role_type=role_type, content=content, chunk_id=chunk_id)
            
            # æ ¸å¿ƒæ”¹è¿›ï¼šå¦‚æœæ£€æµ‹åˆ°æœç´¢æŒ‡ä»¤å·²ç»“æŸï¼ˆå‡ºç° ]ï¼‰ï¼Œç«‹å³åœæ­¢å½“å‰æµï¼Œé˜²æ­¢åç»­ JSON æ³„éœ²
            if "[SEARCH:" in full_content and "]" in full_content[full_content.find("[SEARCH:"): ]:
                logger.info(f"Detected search tag in {agent_name} output, stopping stream to perform search.")
                break
    
    logger.info(f"[{agent_name}] First pass finished. Content length: {len(full_content)}")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æœç´¢
    import re
    queries = re.findall(r'\[SEARCH:\s*(.*?)\]', full_content)
    
    if queries:
        search_query_display = "ã€".join([q.strip() for q in queries])
        logger.info(f"Detected search queries for {agent_name}: {search_query_display}")
        
        # 1. ç«‹å³å‘é€â€œæ­£åœ¨æœç´¢â€çŠ¶æ€åˆ° Web
        if event_type == "agent_action":
            send_web_event(event_type, agent_name=agent_name, role_type=role_type, 
                           content=f"\n\n### SEARCH PROGRESS\n\n> ğŸ” **ç³»ç»Ÿæ­£åœ¨æœç´¢**: {search_query_display}...\n\n", chunk_id=chunk_id)
        
        # 2. æ‰§è¡Œå®é™…æœç´¢
        search_results = search_utils.search_if_needed(full_content)
        
        if search_results:
            logger.info(f"Search results obtained for {agent_name}: {search_results[:200]}...")
            send_web_event("log", content=f"ğŸ” [{agent_name}] æœç´¢ç»“æœ: {search_results[:500]}...")
            
            # 3. å‘é€æœç´¢ç»“æœæ±‡æ€»å’Œå®Œæˆæç¤º
            if event_type == "agent_action":
                combined_content = (
                    f"\n\n### SEARCH PROGRESS\n\n"
                    f"**ğŸŒ è”ç½‘æœç´¢å·²å®Œæˆ**\n\n"
                    f"{search_results}\n\n"
                    f"> âœ… **æ­£åœ¨æ ¹æ®æœç´¢ç»“æœé‡æ–°ç”Ÿæˆæœ€ç»ˆæ–¹æ¡ˆ...**\n\n"
                )
                send_web_event(event_type, agent_name=agent_name, role_type=role_type, 
                               content=combined_content, chunk_id=chunk_id)
            
            # 4. å°†æœç´¢ç»“æœåŠ å…¥ prompt å¹¶é‡æ–°æ‰§è¡Œ
            new_prompt_vars = prompt_vars.copy()
            # å¯»æ‰¾åˆé€‚çš„ key æ¥æ³¨å…¥æœç´¢ç»“æœ
            target_key = None
            for key in ["issue", "inputs", "final_data"]:
                if key in new_prompt_vars:
                    target_key = key
                    break
            
            if target_key:
                new_prompt_vars[target_key] = (
                    f"{new_prompt_vars[target_key]}\n\n"
                    f"ã€è”ç½‘æœç´¢ç»“æœã€‘:\n{search_results}\n\n"
                    f"**é‡è¦æŒ‡ä»¤**ï¼šä½ å·²ç»è·å¾—äº†ä¸€æ¬¡è”ç½‘æœç´¢çš„ç»“æœã€‚è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç›´æ¥è¾“å‡ºæœ€ç»ˆçš„ JSON ç»“æœã€‚**ä¸¥ç¦å†æ¬¡è¾“å‡º [SEARCH:] æ ‡ç­¾**ï¼Œå¦åˆ™ä½ çš„è¾“å‡ºå°†è¢«è§†ä¸ºæ— æ•ˆã€‚"
                )
            
            # ç¬¬äºŒè½®æ‰§è¡Œï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
            full_content = "" # é‡ç½®å†…å®¹
            for chunk in chain.stream(new_prompt_vars):
                reasoning = ""
                content = ""
                if hasattr(chunk, "generation_info") and chunk.generation_info:
                    reasoning = chunk.generation_info.get("reasoning", "")
                
                if hasattr(chunk, "text"):
                    content = chunk.text
                else:
                    content = str(chunk)

                if reasoning:
                    send_web_event(event_type, agent_name=agent_name, role_type=role_type, reasoning=reasoning, chunk_id=chunk_id)
                if content:
                    full_content += content
                    if event_type == "final_report":
                        display_html = full_content.strip()
                        if display_html.startswith("```html"): display_html = display_html[7:]
                        elif display_html.startswith("```"): display_html = display_html[3:]
                        if display_html.endswith("```"): display_html = display_html[:-3]
                        send_web_event(event_type, content=display_html.strip())
                    else:
                        send_web_event(event_type, agent_name=agent_name, role_type=role_type, content=content, chunk_id=chunk_id)
                    
                    # ç¬¬äºŒè½®ä¹Ÿå¢åŠ  break é€»è¾‘ï¼Œé˜²æ­¢ agent å¼ºè¡Œå†æ¬¡æœç´¢å¯¼è‡´æ­»å¾ªç¯
                    if "[SEARCH:" in full_content and "]" in full_content[full_content.find("[SEARCH:"): ]:
                        logger.warning(f"Agent {agent_name} tried to search AGAIN in the second run. Stopping.")
                        break
            
            logger.info(f"[{agent_name}] Second pass finished. Content length: {len(full_content)}")
                
    return full_content, search_results

def make_planner_chain(model_config: Dict[str, Any]):
    llm = AdapterLLM(backend_config=ModelConfig(**model_config))
    prompt = PromptTemplate.from_template(
        """
        **IMPORTANT: You MUST respond in the SAME LANGUAGE as the input "è®®é¢˜/æŒ‡ä»¤" (e.g., if the input is in Chinese, your entire response must be in Chinese).**
        **CRITICAL: Your internal thinking/reasoning process MUST also be in the SAME LANGUAGE as the input.**

        ä½ æ˜¯ç­–è®ºå®¶ï¼ˆåˆ›æ„è€…ï¼‰ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è®®é•¿çš„æŒ‡ä»¤äº§å‡ºæˆ–è¿­ä»£å¯æ‰§è¡Œæ–¹æ¡ˆã€‚
        
        **äº‹å®å‡†ç¡®æ€§åŸåˆ™**ï¼šä½ å¿…é¡»ç¡®ä¿è¾“å‡ºçš„æ‰€æœ‰æ•°æ®ã€æ”¿ç­–ã€æŠ€æœ¯ç»†èŠ‚å‡æœ‰æ®å¯æŸ¥ã€‚**ä¸¥ç¦èƒ¡ç¼–ä¹±é€ **ï¼Œä¸¥ç¦è™šæ„ä¸å­˜åœ¨çš„æ³•å¾‹æ³•è§„æˆ–æŠ€æœ¯æŒ‡æ ‡ã€‚
        
        **è”ç½‘æœç´¢ä¼˜å…ˆåŸåˆ™**ï¼šä¸ºäº†ç¡®ä¿æ–¹æ¡ˆçš„å…ˆè¿›æ€§ä¸äº‹å®å‡†ç¡®æ€§ï¼Œ**å¼ºçƒˆå»ºè®®ä½ åœ¨ç¬¬ä¸€è½®æˆ–é¢å¯¹ä¸ç†Ÿæ‚‰çš„é¢†åŸŸæ—¶ï¼Œä¼˜å…ˆä½¿ç”¨æœç´¢åŠŸèƒ½**ã€‚
        
        **è”ç½‘æœç´¢æŠ€èƒ½**ï¼šå¦‚æœä½ éœ€è¦äº†è§£æœ€æ–°çš„äº‹å®ã€æ•°æ®æˆ–èƒŒæ™¯ä¿¡æ¯ï¼Œå¯ä»¥åœ¨è¾“å‡º JSON ä¹‹å‰ï¼Œå…ˆè¾“å‡º `[SEARCH: å…·ä½“çš„æœç´¢æŸ¥è¯¢è¯­å¥]`ã€‚
        **æœç´¢å»ºè®®**ï¼š
        1. è¯·ä½¿ç”¨**è‡ªç„¶è¯­è¨€çŸ­è¯­**ï¼ˆå¦‚ `[SEARCH: 2025å¹´åŒ—äº¬æˆ¿åœ°äº§æœ€æ–°æ”¿ç­–]`ï¼‰ã€‚
        2. **ä¸¥ç¦å°†å…³é”®è¯æ‹†å¾—è¿‡ç»†**ï¼ˆä¸è¦ä½¿ç”¨ç©ºæ ¼åˆ†éš”æ¯ä¸€ä¸ªè¯ï¼‰ã€‚
        3. **æç®€åŸåˆ™**ï¼šæœç´¢è¯å¿…é¡»æ§åˆ¶åœ¨ **20ä¸ªå­—ä»¥å†…**ã€‚è¯·æç‚¼æœ€æ ¸å¿ƒçš„å…³é”®è¯çŸ­è¯­ï¼Œ**ä¸¥ç¦ç›´æ¥å¤åˆ¶èƒŒæ™¯æˆ–é•¿å¥**ã€‚
        4. **ä¸¥ç¦åŒ…å«æ— æ„ä¹‰çš„å¡«å……è¯**ï¼ˆå¦‚â€œå†…å®¹â€ã€â€œæ±‡æ€»â€ã€â€œåˆ—è¡¨â€ã€â€œæœ‰å“ªäº›â€ï¼‰ã€‚
        **é‡è¦ï¼šå¦‚æœä½ å†³å®šæœç´¢ï¼Œè¯·ä»…è¾“å‡ºæœç´¢æŒ‡ä»¤å¹¶ç«‹å³åœæ­¢ï¼Œä¸è¦è¾“å‡ºä»»ä½• JSON å†…å®¹ã€‚** ç³»ç»Ÿè¿”å›ç»“æœåï¼Œä½ ä¼šé‡æ–°è·å¾—æœºä¼šè¾“å‡ºæœ€ç»ˆæ–¹æ¡ˆã€‚
        æ³¨æ„ï¼šè¯·åŠ¡å¿…æä¾›å…·ä½“çš„æœç´¢å…³é”®è¯ï¼Œä¸è¦ç›´æ¥ç…§æŠ„ç¤ºä¾‹ã€‚æ¯è½®ä½ åªèƒ½ä½¿ç”¨ä¸€æ¬¡æœç´¢ã€‚
        
        ç›²è¯„æ¨¡å¼ï¼šä¸å¾—å‚è€ƒæˆ–å¼•ç”¨å…¶ä»–ç­–è®ºå®¶/ç›‘å¯Ÿå®˜çš„è§‚ç‚¹ã€‚
        
        å¦‚æœä½ æ”¶åˆ°äº†â€œä¸Šä¸€è½®æ–¹æ¡ˆâ€å’Œâ€œç›‘å¯Ÿå®˜åé¦ˆâ€ï¼Œè¯·åœ¨åŸæœ‰æ–¹æ¡ˆåŸºç¡€ä¸Šè¿›è¡Œé’ˆå¯¹æ€§ä¿®æ­£å’Œè¿­ä»£ï¼Œè€Œä¸æ˜¯æ¨ç¿»é‡æ¥ã€‚
        
        ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼š
        {{
            "id": "{planner_id}",
            "core_idea": "æ–¹æ¡ˆæ ¸å¿ƒæ€è·¯",
            "steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
            "feasibility": {{
                "advantages": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
                "requirements": ["èµ„æºéœ€æ±‚1", "èµ„æºéœ€æ±‚2"]
            }},
            "limitations": ["å±€é™æ€§1", "å±€é™æ€§2"]
        }}
        
        è®®é¢˜/æŒ‡ä»¤ï¼š{issue}
        ä¸Šä¸€è½®æ–¹æ¡ˆï¼š{previous_plan}
        ç›‘å¯Ÿå®˜åé¦ˆï¼š{feedback}
        """
    )
    return prompt | llm


def make_auditor_chain(model_config: Dict[str, Any]):
    llm = AdapterLLM(backend_config=ModelConfig(**model_config))
    prompt = PromptTemplate.from_template(
        """
        **IMPORTANT: You MUST respond in the SAME LANGUAGE as the input "è®®é¢˜èƒŒæ™¯" (e.g., if the input is in Chinese, your entire response must be in Chinese).**
        **CRITICAL: Your internal thinking/reasoning process MUST also be in the SAME LANGUAGE as the input.**

        ä½ æ˜¯ç›‘å¯Ÿå®˜ï¼ˆè´¨ç–‘è€…ï¼‰ã€‚æ”¶åˆ°è®®é•¿çš„â€œè´¨ç–‘å®¡æ ¸â€æŒ‡ä»¤åï¼Œé’ˆå¯¹æ¯ä¸ªæ–¹æ¡ˆç»™å‡ºé€é¡¹è´¨ç–‘ã€æ”¹è¿›å»ºè®®ä¸è¯„çº§ã€‚
        
        **äº‹å®å‡†ç¡®æ€§åŸåˆ™**ï¼šä½ çš„å®¡è®¡æ„è§å¿…é¡»åŸºäºçœŸå®çš„äº‹å®å’Œæ•°æ®ã€‚**ä¸¥ç¦èƒ¡ç¼–ä¹±é€ **ï¼Œä¸¥ç¦è™šæ„ä¸å­˜åœ¨çš„é£é™©æˆ–æ ‡å‡†ã€‚
        
        **è”ç½‘æœç´¢ä¼˜å…ˆåŸåˆ™**ï¼šä¸ºäº†æä¾›æ›´å…·æƒå¨æ€§çš„å®¡è®¡æ„è§ï¼Œ**å¼ºçƒˆå»ºè®®ä½ é’ˆå¯¹æ–¹æ¡ˆä¸­çš„å…³é”®æ•°æ®æˆ–æŠ€æœ¯è·¯å¾„è¿›è¡Œæœç´¢æ ¸å®**ã€‚
        
        **è”ç½‘æœç´¢æŠ€èƒ½**ï¼šå¦‚æœä½ éœ€è¦æ ¸å®æ–¹æ¡ˆä¸­çš„äº‹å®ã€æ•°æ®æˆ–å¯è¡Œæ€§ï¼Œå¯ä»¥åœ¨è¾“å‡º JSON ä¹‹å‰ï¼Œå…ˆè¾“å‡º `[SEARCH: å…·ä½“çš„æœç´¢æŸ¥è¯¢è¯­å¥]`ã€‚
        **æœç´¢å»ºè®®**ï¼š
        1. è¯·ä½¿ç”¨**è‡ªç„¶è¯­è¨€çŸ­è¯­**ï¼ˆå¦‚ `[SEARCH: æŸæŸæŠ€æœ¯çš„æœ€æ–°è¡Œä¸šæ ‡å‡†]`ï¼‰ã€‚
        2. **ä¸¥ç¦å°†å…³é”®è¯æ‹†å¾—è¿‡ç»†**ï¼ˆä¸è¦ä½¿ç”¨ç©ºæ ¼åˆ†éš”æ¯ä¸€ä¸ªè¯ï¼‰ã€‚
        3. **æç®€åŸåˆ™**ï¼šæœç´¢è¯å¿…é¡»æ§åˆ¶åœ¨ **20ä¸ªå­—ä»¥å†…**ã€‚è¯·æç‚¼æœ€æ ¸å¿ƒçš„å…³é”®è¯çŸ­è¯­ï¼Œ**ä¸¥ç¦ç›´æ¥å¤åˆ¶èƒŒæ™¯æˆ–é•¿å¥**ã€‚
        4. **ä¸¥ç¦åŒ…å«æ— æ„ä¹‰çš„å¡«å……è¯**ï¼ˆå¦‚â€œå†…å®¹â€ã€â€œæ±‡æ€»â€ã€â€œåˆ—è¡¨â€ã€â€œæœ‰å“ªäº›â€ï¼‰ã€‚
        **é‡è¦ï¼šå¦‚æœä½ å†³å®šæœç´¢ï¼Œè¯·ä»…è¾“å‡ºæœç´¢æŒ‡ä»¤å¹¶ç«‹å³åœæ­¢ï¼Œä¸è¦è¾“å‡ºä»»ä½• JSON å†…å®¹ã€‚** ç³»ç»Ÿè¿”å›ç»“æœåï¼Œä½ ä¼šé‡æ–°è·å¾—æœºä¼šè¾“å‡ºæœ€ç»ˆå®¡è®¡ã€‚
        æ³¨æ„ï¼šè¯·åŠ¡å¿…æä¾›å…·ä½“çš„æœç´¢å…³é”®è¯ï¼Œä¸è¦ç›´æ¥ç…§æŠ„ç¤ºä¾‹ã€‚æ¯è½®ä½ åªèƒ½ä½¿ç”¨ä¸€æ¬¡æœç´¢ã€‚
        
        ç›²è¯„æ¨¡å¼ï¼šä¸å¾—å‚è€ƒå…¶ä»–ç›‘å¯Ÿå®˜è¾“å‡ºã€‚
        ## æ³¨æ„ä¸è¦æå‡ºä¸è®®é¢˜æ— å…³çš„è´¨ç–‘ç‚¹ã€‚
        
        ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼š
        {{
            "auditor_id": "{auditor_id}",
            "reviews": [
                {{
                    "plan_id": "æ–¹æ¡ˆID",
                    "issues": ["è´¨ç–‘ç‚¹1", "è´¨ç–‘ç‚¹2"],
                    "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
                    "rating": "è¯„çº§(ä¼˜ç§€/åˆæ ¼/éœ€é‡æ„/ä¸å¯è¡Œ)"
                }}
            ],
            "summary": "æ±‡æ€»æ‰€æœ‰æ–¹æ¡ˆçš„ä¼˜åŠ£åŠ¿æ’åºåŠæ ¸å¿ƒäº‰è®®ç‚¹"
        }}
        
        æ–¹æ¡ˆåˆ—è¡¨ï¼š{plans}
        è®®é¢˜èƒŒæ™¯ï¼š{issue}
        """
    )
    return prompt | llm


def make_leader_chain(model_config: Dict[str, Any]):
    llm = AdapterLLM(backend_config=ModelConfig(**model_config))
    prompt = PromptTemplate.from_template(
        """
        **IMPORTANT: You MUST respond in the SAME LANGUAGE as the input "è¾“å…¥ä¿¡æ¯" (e.g., if the input is in Chinese, your entire response must be in Chinese).**
        **CRITICAL: Your internal thinking/reasoning process MUST also be in the SAME LANGUAGE as the input.**

        ä½ æ˜¯æœ¬æ¬¡è®¨è®ºçš„è®®é•¿ï¼ˆç»„ç»‡è€…ï¼‰ã€‚
        ä»»åŠ¡ï¼š
        1) æ‹†è§£ç”¨æˆ·è®®é¢˜ï¼Œæå–æ ¸å¿ƒç›®æ ‡ä¸å…³é”®é—®é¢˜ï¼›
        2) ä¸ºæœ¬æ¬¡è®®é¢˜è®¾è®¡ä¸€ä»½æœ€ç»ˆæŠ¥å‘Šçš„ç»“æ„ï¼ˆreport_designï¼‰ã€‚**æ ¸å¿ƒè¦æ±‚ï¼šå¤§çº²å¿…é¡»ç´§æ‰£ç”¨æˆ·åŸå§‹é—®é¢˜ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡å—éƒ½èƒ½ä¸ºå›ç­”è¯¥é—®é¢˜æä¾›å®è´¨æ€§è´¡çŒ®ï¼Œä¸¥ç¦åç¦»ä¸»é¢˜**ï¼›
        3) åœ¨æ¯è½®ç»“æŸåï¼Œæ ¹æ®å¤šä½ç­–è®ºå®¶/ç›‘å¯Ÿå®˜çš„JSONè¾“å‡ºè¿›è¡Œå»é‡ã€æ±‡æ€»ä¸åˆ¤å®šï¼›
        4) åˆ é™¤ä¸è®®é¢˜æ— å…³çš„å†…å®¹ï¼›
        5) ä»…ä»¥JSONæ ¼å¼è¾“å‡ºæ±‡æ€»ç»“æœã€‚
        
        **äº‹å®å‡†ç¡®æ€§åŸåˆ™**ï¼šä½œä¸ºè®®é•¿ï¼Œä½ å¿…é¡»ç¡®ä¿å¯¹è®®é¢˜çš„æ‹†è§£å’Œæ±‡æ€»åŸºäºå®¢è§‚äº‹å®ã€‚**ä¸¥ç¦èƒ¡ç¼–ä¹±é€ **ï¼Œä¸¥ç¦è™šæ„è¡Œä¸šèƒŒæ™¯æˆ–è™šå‡å…±è¯†ã€‚
        
        **è”ç½‘æœç´¢ä¼˜å…ˆåŸåˆ™**ï¼šä½œä¸ºè®®é•¿ï¼Œ**å¼ºçƒˆå»ºè®®ä½ åœ¨æ‹†è§£è®®é¢˜é˜¶æ®µä¼˜å…ˆæœç´¢è¡Œä¸šèƒŒæ™¯æˆ–æœ€æ–°åŠ¨æ€**ï¼Œä»¥ç¡®ä¿è®¨è®ºæ–¹å‘çš„ä¸“ä¸šæ€§ã€‚
        
        **è”ç½‘æœç´¢æŠ€èƒ½**ï¼šå¦‚æœä½ éœ€è¦äº†è§£è®®é¢˜çš„èƒŒæ™¯çŸ¥è¯†æˆ–è¡Œä¸šæ ‡å‡†ï¼Œå¯ä»¥åœ¨è¾“å‡º JSON ä¹‹å‰ï¼Œå…ˆè¾“å‡º `[SEARCH: å…·ä½“çš„æœç´¢æŸ¥è¯¢è¯­å¥]`ã€‚
        **æœç´¢å»ºè®®**ï¼š
        1. è¯·ä½¿ç”¨**è‡ªç„¶è¯­è¨€çŸ­è¯­**ï¼ˆå¦‚ `[SEARCH: 2025å¹´äººå·¥æ™ºèƒ½è¡Œä¸šæ ‡å‡†]`ï¼‰ã€‚
        2. **ä¸¥ç¦å°†å…³é”®è¯æ‹†å¾—è¿‡ç»†**ï¼ˆä¸è¦ä½¿ç”¨ç©ºæ ¼åˆ†éš”æ¯ä¸€ä¸ªè¯ï¼‰ã€‚
        3. **æç®€åŸåˆ™**ï¼šæœç´¢è¯å¿…é¡»æ§åˆ¶åœ¨ **20ä¸ªå­—ä»¥å†…**ã€‚è¯·æç‚¼æœ€æ ¸å¿ƒçš„å…³é”®è¯çŸ­è¯­ï¼Œ**ä¸¥ç¦ç›´æ¥å¤åˆ¶èƒŒæ™¯æˆ–é•¿å¥**ã€‚
        4. **ä¸¥ç¦åŒ…å«æ— æ„ä¹‰çš„å¡«å……è¯**ï¼ˆå¦‚â€œå†…å®¹â€ã€â€œæ±‡æ€»â€ã€â€œåˆ—è¡¨â€ã€â€œæœ‰å“ªäº›â€ï¼‰ã€‚
        
        **æ³¨æ„**ï¼š
        - **é—®é¢˜å¯¼å‘**ï¼šåœ¨è®¾è®¡ `report_design` æ—¶ï¼Œè¯·åå¤æ£€æŸ¥ï¼šå¦‚æœæŒ‰ç…§è¿™ä¸ªå¤§çº²ç”ŸæˆæŠ¥å‘Šï¼Œæ˜¯å¦èƒ½å®Œæ•´ã€ç›´æ¥åœ°å›ç­”ç”¨æˆ·æœ€åˆæå‡ºçš„é—®é¢˜ï¼Ÿ
        - å¦‚æœè¾“å…¥ä¸­åŒ…å« `original_goal`ï¼Œè¯·åŠ¡å¿…åœ¨ `decomposition` ä¸­ä¿ç•™è¯¥æ ¸å¿ƒç›®æ ‡ï¼Œä¸è¦éšæ„ä¿®æ”¹ã€‚
        - å¦‚æœè¾“å…¥ä¸­åŒ…å« `previous_decomposition`ï¼Œè¯·å‚è€ƒä¹‹å‰çš„æŠ¥å‘Šå¤§çº²è®¾è®¡ï¼ˆreport_designï¼‰ï¼Œé™¤éæœ‰æå…¶é‡è¦çš„ç†ç”±ï¼Œå¦åˆ™**ä¸¥ç¦å¤§å¹…ä¿®æ”¹å¤§çº²ç»“æ„**ï¼Œä»¥ä¿æŒè®®äº‹çš„ä¸€è‡´æ€§ã€‚ä½ å¯ä»¥åœ¨åŸæœ‰å¤§çº²åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒæˆ–æ·±åŒ–ã€‚
        
        ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼š
        {{
            "round": 1,
            "decomposition": {{
                "core_goal": "æœ¬æ¬¡è®®é¢˜çš„æ ¸å¿ƒç›®æ ‡",
                "key_questions": ["å…³é”®é—®é¢˜1", "å…³é”®é—®é¢˜2"],
                "boundaries": "è®¨è®ºè¾¹ç•Œ",
                "report_design": {{
                    "æ¨¡å—å1": "è¯¥æ¨¡å—åº”å¦‚ä½•ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æè¿°",
                    "æ¨¡å—å2": "è¯¥æ¨¡å—åº”å¦‚ä½•ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æè¿°"
                }}
            }},
            "instructions": "æœ¬è½®åä½œæŒ‡ä»¤ï¼ˆå¦‚ï¼šè¯·ç­–è®ºå®¶èšç„¦XXæ–¹å‘ï¼‰",
            "summary": {{
                "consensus": ["å…±è¯†ç»“è®º1", "å…±è¯†ç»“è®º2"],
                "controversies": ["äº‰è®®ç‚¹1", "äº‰è®®ç‚¹2"]
            }}
        }}
        
        æ³¨æ„ï¼š
        - decomposition å¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ˆdictï¼‰ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²ã€‚
        - summary å¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ˆdictï¼‰ï¼ŒåŒ…å« consensus å’Œ controversies ä¸¤ä¸ªåˆ—è¡¨ã€‚
        - å¦‚æœæ˜¯é¦–æ¬¡æ‹†è§£è®®é¢˜ï¼Œsummary éƒ¨åˆ†å¯ä»¥ä¸ºç©ºåˆ—è¡¨ã€‚
        
        å½“å‰æ—¶é—´ï¼š{current_time}
        è¾“å…¥ä¿¡æ¯ï¼ˆè®®é¢˜æˆ–ä¸Šè½®æ–¹æ¡ˆä¸å®¡æ ¸æ„è§ï¼‰ï¼š{inputs}
        """
    )
    return prompt | llm


def make_reporter_chain(model_config: Dict[str, Any]):
    llm = AdapterLLM(backend_config=ModelConfig(**model_config))
    prompt = PromptTemplate.from_template(
        """
        **IMPORTANT: You MUST respond in the SAME LANGUAGE as the input "å®Œæ•´è®®äº‹è®°å½•" (e.g., if the input is in Chinese, your entire response must be in Chinese).**

        ä½ æ˜¯é¦–å¸­æ–¹æ¡ˆæ¶æ„å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è®®äº‹è¿‡ç¨‹çš„å®Œæ•´è®°å½•ï¼Œæç‚¼å¹¶æ•´åˆå‡ºä¸€å¥—æœ€ç»ˆçš„ã€å…·å¤‡æé«˜å¯æ“ä½œæ€§çš„å»ºè®®æ–¹æ¡ˆã€‚
        
        **æ ¸å¿ƒè¦æ±‚**ï¼š
        1. **ç¦æ­¢ç´¯è¿°**ï¼šä¸è¦æåŠâ€œç­–è®ºå®¶Aè¯´äº†ä»€ä¹ˆâ€ã€â€œç›‘å¯Ÿå®˜Bè´¨ç–‘äº†ä»€ä¹ˆâ€ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆè¾¾æˆçš„å…±è¯†æ–¹æ¡ˆã€‚
        2. **è¾“å‡ºæ ¼å¼**ï¼šå¿…é¡»è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ã€è‡ªåŒ…å«çš„ HTML é¡µé¢ä»£ç ï¼ˆåŒ…å« <!DOCTYPE html>, <html>, <head>, <style>, <body>ï¼‰ã€‚
        3. **ç¦æ­¢ Markdown**ï¼šç»å¯¹ä¸è¦å°† HTML ä»£ç åŒ…è£¹åœ¨ ```html æˆ– ``` ç­‰ Markdown ä»£ç å—æ ‡ç­¾ä¸­ï¼Œç›´æ¥è¾“å‡º HTML æºç ã€‚
        4. **è§†è§‰è®¾è®¡**ï¼šä½¿ç”¨ç°ä»£ã€ç®€çº¦ã€ä¸“ä¸šçš„ UI è®¾è®¡ã€‚åˆ©ç”¨ CSS æ„å»ºæ¸…æ™°çš„å¡ç‰‡å¸ƒå±€ã€æ­¥éª¤æ¡æˆ–ä¿¡æ¯å›¾è¡¨ã€‚
        5. **äº¤äº’æ€§**ï¼šå¯ä»¥åœ¨ HTML ä¸­åŠ å…¥ç®€å•çš„ JSï¼ˆå¦‚ç‚¹å‡»å±•å¼€è¯¦æƒ…ã€åˆ‡æ¢æ ‡ç­¾ç­‰ï¼‰ä»¥å¢å¼ºå±•ç¤ºæ•ˆæœã€‚
        6. **ç»“æ„éµå¾ª**ï¼šè¯·åŠ¡å¿…éµå¾ªè®®é•¿è®¾è®¡çš„æŠ¥å‘Šç»“æ„ï¼ˆreport_designï¼‰è¿›è¡Œå†…å®¹ç»„ç»‡ã€‚
        7. **è¯­è¨€ä¸€è‡´æ€§**ï¼šæŠ¥å‘Šçš„æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æŒ‰é’®ã€æ ‡ç­¾ã€æ­£æ–‡ï¼‰å¿…é¡»ä½¿ç”¨ä¸åŸå§‹è®®é¢˜ç›¸åŒçš„è¯­è¨€ã€‚
        8. **å¼•ç”¨ä¸å‚è€ƒèµ„æ–™ï¼ˆä¸¥ç¦è™šæ„é“¾æ¥ï¼‰**ï¼š
            - **çœŸå®æ€§åŸåˆ™**ï¼š**ä¸¥ç¦èƒ¡ç¼–ä¹±é€ ä»»ä½•é“¾æ¥ã€æ•°æ®æˆ–äº‹å®**ã€‚
            - **è¡Œå†…å¼•ç”¨**ï¼šä»…å¼•ç”¨â€œè”ç½‘æœç´¢å‚è€ƒèµ„æ–™â€ä¸­æä¾›çš„çœŸå® URLã€‚**ä¸¥ç¦è™šæ„ç±»ä¼¼ `https://developer.aliyun.com/article/xxxxxx` è¿™ç§å ä½ç¬¦é“¾æ¥**ã€‚
            - **å¼•ç”¨æ ¼å¼**ï¼šåœ¨æŠ¥å‘Šæ­£æ–‡ä¸­å¼•ç”¨åˆ°è”ç½‘æœç´¢æä¾›çš„ä¿¡æ¯æ—¶ï¼Œè¯·åŠ¡å¿…åœ¨å¯¹åº”æ–‡å­—ååŠ ä¸Šè¶…é“¾æ¥å¼•ç”¨ï¼Œä¾‹å¦‚ï¼š`<a href="URL" target="_blank">[1]</a>`ã€‚
            - **æœ«å°¾åˆ—è¡¨**ï¼šåœ¨æŠ¥å‘Šæœ«å°¾æ·»åŠ â€œå‚è€ƒèµ„æ–™â€ç« èŠ‚ï¼Œåˆ—å‡ºæ‰€æœ‰å‚è€ƒé“¾æ¥ã€‚
        9. **ç¦æ­¢åºŸè¯**ï¼šä¸è¦åŒ…å«ä»»ä½•å…³äºæŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹çš„æè¿°ï¼ˆå¦‚â€œåŸºäºå¤šè½®è®¨è®ºå½¢æˆâ€ã€â€œæœ¬æŠ¥å‘Šæ•´åˆè‡ª...â€ï¼‰ã€ç‰ˆæƒå£°æ˜ã€è®²è§£æ—¶é•¿å»ºè®®æˆ–ä»»ä½•å‰è¨€/åè®°ã€‚ç›´æ¥ä»æŠ¥å‘Šæ ‡é¢˜å’Œæ­£æ–‡å†…å®¹å¼€å§‹ã€‚
        
        è¯·ç¡®ä¿ HTML ä»£ç åœ¨ <iframe> ä¸­èƒ½å®Œç¾æ¸²æŸ“ã€‚
        
        å®Œæ•´è®®äº‹è®°å½•ï¼ˆåŒ…å«è®®é•¿çš„æŠ¥å‘Šè®¾è®¡ï¼‰ï¼š{final_data}
        
        è”ç½‘æœç´¢å‚è€ƒèµ„æ–™ï¼ˆè¯·åŠ¡å¿…æ•´åˆè¿›æŠ¥å‘Šæœ«å°¾ï¼‰ï¼š{search_references}
        """
    )
    return prompt | llm


def run_full_cycle(issue_text: str, model_config: Dict[str, Any] = None, max_rounds: int = 3, num_planners: int = 2, num_auditors: int = 2, agent_configs: Dict[str, Any] = None) -> Dict[str, Any]:
    """Run a multi-round LangChain-driven cycle: leader decomposes, planners generate plans, auditors review, leader summarizes.
    """
    # 1. åˆå§‹åŒ– Session å’Œ Workspace
    session_id = datetime.now().strftime("%Y%m%d_%H%M%S") + "_" + str(uuid.uuid4())[:8]
    workspace_path = os.path.join(os.getcwd(), "workspaces", session_id)
    os.makedirs(workspace_path, exist_ok=True)
    logger.info(f"[cycle] Session ID: {session_id}, Workspace: {workspace_path}")

    # é‡ç½® Web é¢æ¿
    try:
        requests.post("http://127.0.0.1:5000/api/reset", timeout=1)
    except:
        pass

    # å‘é€å¯åŠ¨äº‹ä»¶
    send_web_event("system_start", message=f"è®®äº‹å…å¯åŠ¨ (ID: {session_id})ï¼šæ­£åœ¨å‡†å¤‡å…ƒè€å¸­ä½...", issue=issue_text, session_id=session_id)

    model_config = model_config or {"type": model_adapter.config.MODEL_BACKEND, "model": model_adapter.config.MODEL_NAME}
    agent_configs = agent_configs or {}
    
    max_retries = 3
    
    # åˆå§‹åŒ–å„è§’è‰²çš„ Chain
    leader_cfg = agent_configs.get("leader") or model_config
    leader_chain = make_leader_chain(leader_cfg)
    
    reporter_cfg = agent_configs.get("reporter") or model_config
    reporter_chain = make_reporter_chain(reporter_cfg)

    # ç­–è®ºå®¶å’Œç›‘å¯Ÿå®˜çš„ Chain åˆ—è¡¨
    planner_chains = []
    for i in range(num_planners):
        # ä¼˜å…ˆä» agent_configs è·å– planner_iï¼Œå¦åˆ™ä½¿ç”¨å…¨å±€ model_config
        p_cfg = agent_configs.get(f"planner_{i}") or model_config
        planner_chains.append(make_planner_chain(p_cfg))
        
    auditor_chains = []
    for i in range(num_auditors):
        # ä¼˜å…ˆä» agent_configs è·å– auditor_iï¼Œå¦åˆ™ä½¿ç”¨å…¨å±€ model_config
        a_cfg = agent_configs.get(f"auditor_{i}") or model_config
        auditor_chains.append(make_auditor_chain(a_cfg))

    # 1. Leader initial decomposition
    logger.info("[cycle] è®®é•¿æ­£åœ¨è¿›è¡Œåˆå§‹è®®é¢˜æ‹†è§£...")
    decomposition = {
        "core_goal": "è§£æå¤±è´¥",
        "key_questions": [],
        "boundaries": "æœªçŸ¥",
    }
    all_search_references = []
    for attempt in range(max_retries):
        try:
            logger.info(f"[cycle] è®®é•¿æ­£åœ¨è°ƒç”¨æ¨¡å‹è¿›è¡Œæ‹†è§£ (å°è¯• {attempt + 1}/{max_retries})...")
            current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            out, search_res = stream_agent_output(leader_chain, {"inputs": issue_text, "current_time": current_time_str}, "è®®é•¿", "Leader")
            if search_res:
                all_search_references.append(search_res)
            
            cleaned = clean_json_string(out)
            if not cleaned:
                logger.error(f"[cycle] è®®é•¿è¾“å‡ºä¸ºç©ºæˆ–ä¸åŒ…å« JSONã€‚åŸå§‹è¾“å‡º: {out}")
                raise ValueError("è®®é•¿æœªè¿”å›æœ‰æ•ˆçš„ JSON æ‹†è§£ç»“æœ")
                
            parsed = json.loads(cleaned)
            summary = schemas.LeaderSummary(**parsed)
            decomposition = summary.decomposition.dict()
            
            # ä¿å­˜åˆå§‹æ‹†è§£ç»“æœ
            with open(os.path.join(workspace_path, "decomposition.json"), "w", encoding="utf-8") as f:
                json.dump(decomposition, f, ensure_ascii=False, indent=4)
            
            logger.info(f"[cycle] è®®é•¿æ‹†è§£æˆåŠŸ (å°è¯• {attempt + 1})")
            break
        except Exception as e:
            logger.warning(f"[cycle] è®®é•¿æ‹†è§£å°è¯• {attempt + 1} å¤±è´¥: {e}")
            logger.error(traceback.format_exc())

    history = []
    current_instructions = f"è®®é¢˜: {issue_text}\næ ¸å¿ƒç›®æ ‡: {decomposition['core_goal']}\nå…³é”®é—®é¢˜: {decomposition['key_questions']}"
    
    last_plans_map = {i: None for i in range(1, num_planners + 1)}
    last_audits = []
    user_interventions = []

    for r in range(1, max_rounds + 1):
        logger.info(f"=== å¼€å§‹ç¬¬ {r} è½®è®¨è®º ===")
        send_web_event("round_start", round=r)
        
        # æ£€æŸ¥ç”¨æˆ·å¹²é¢„
        intervention_file = os.path.join(workspace_path, "user_intervention.json")
        if os.path.exists(intervention_file):
            try:
                with open(intervention_file, "r", encoding="utf-8") as f:
                    intervention_data = json.load(f)
                    user_msg = intervention_data.get("content")
                    if user_msg:
                        logger.info(f"[round {r}] æ”¶åˆ°ç”¨æˆ·å¹²é¢„: {user_msg}")
                        # å°†å¹²é¢„åŠ å…¥æŒ‡ä»¤
                        current_instructions += f"\n\n[ç”¨æˆ·å¹²é¢„æŒ‡ä»¤]: {user_msg}"
                        user_interventions.append(user_msg)
                        # è®°å½•åˆ° history ä¸­
                        history.append({
                            "round": r,
                            "type": "user_intervention",
                            "content": user_msg
                        })
                os.remove(intervention_file)
            except Exception as e:
                logger.error(f"å¤„ç†ç”¨æˆ·å¹²é¢„å¤±è´¥: {e}")

        def execute_planner(i):
            logger.info(f"[round {r}] ç­–è®ºå®¶ {i} æ­£åœ¨ç”Ÿæˆ/è¿­ä»£æ–¹æ¡ˆ...")
            feedback = "æ— ï¼ˆé¦–è½®æˆ–ä¸Šè½®æ— åé¦ˆï¼‰"
            prev_plan = last_plans_map[i]
            if prev_plan and last_audits:
                relevant_feedbacks = []
                target_id = prev_plan.get("id")
                for audit in last_audits:
                    if isinstance(audit, dict) and "reviews" in audit:
                        for review in audit["reviews"]:
                            if review.get("plan_id") == target_id:
                                relevant_feedbacks.append(f"è¯„çº§: {review.get('rating')}\nè´¨ç–‘: {review.get('issues')}\nå»ºè®®: {review.get('suggestions')}")
                if relevant_feedbacks:
                    feedback = "\n---\n".join(relevant_feedbacks)

            prompt_vars = {
                "planner_id": f"ç­–è®ºå®¶ {i}-æ–¹æ¡ˆ 1",
                "issue": current_instructions,
                "previous_plan": json.dumps(prev_plan, ensure_ascii=False) if prev_plan else "æ— ",
                "feedback": feedback
            }
            
            for attempt in range(max_retries):
                try:
                    out, search_res = stream_agent_output(planner_chains[i-1], prompt_vars, f"ç­–è®ºå®¶ {i}", "Planner")
                    if search_res:
                        all_search_references.append(search_res)
                    
                    cleaned = clean_json_string(out)
                    if not cleaned:
                        raise ValueError("ç­–è®ºå®¶è¾“å‡ºä¸ºç©ºæˆ–ä¸åŒ…å« JSON")
                        
                    parsed = json.loads(cleaned)
                    p = schemas.PlanSchema(**parsed)
                    plan_dict = p.dict()
                    logger.info(f"[round {r}] ç­–è®ºå®¶ {i} æˆåŠŸ (å°è¯• {attempt + 1})")
                    return plan_dict
                except Exception as e:
                    logger.warning(f"[round {r}] ç­–è®ºå®¶ {i} å°è¯• {attempt + 1} å¤±è´¥: {e}")
                    logger.error(traceback.format_exc())
                    if attempt == max_retries - 1:
                        return {"text": out if 'out' in locals() else "N/A", "error": str(e), "id": f"ç­–è®ºå®¶{i}-é”™è¯¯"}
            return None

        with ThreadPoolExecutor(max_workers=num_planners) as executor:
            planner_results = list(executor.map(execute_planner, range(1, num_planners + 1)))
        
        plans = []
        for i, res in enumerate(planner_results, 1):
            if res:
                plans.append(res)
                last_plans_map[i] = res

        def execute_auditor(j):
            logger.info(f"[round {r}] ç›‘å¯Ÿå®˜ {j} æ­£åœ¨å®¡æ ¸æ–¹æ¡ˆ...")
            prompt_vars = {
                "auditor_id": f"ç›‘å¯Ÿå®˜ {j}",
                "plans": json.dumps(plans, ensure_ascii=False),
                "issue": f"æ ¸å¿ƒç›®æ ‡: {decomposition['core_goal']}\nå…³é”®é—®é¢˜: {decomposition['key_questions']}"
            }
            
            for attempt in range(max_retries):
                try:
                    out, search_res = stream_agent_output(auditor_chains[i-1], prompt_vars, f"ç›‘å¯Ÿå®˜ {i}", "Auditor")
                    if search_res:
                        all_search_references.append(search_res)
                    
                    cleaned = clean_json_string(out)
                    if not cleaned:
                        raise ValueError("ç›‘å¯Ÿå®˜è¾“å‡ºä¸ºç©ºæˆ–ä¸åŒ…å« JSON")
                        
                    parsed = json.loads(cleaned)
                    a = schemas.AuditorSchema(**parsed)
                    logger.info(f"[round {r}] ç›‘å¯Ÿå®˜ {j} æˆåŠŸ (å°è¯• {attempt + 1})")
                    return a.dict()
                except Exception as e:
                    logger.warning(f"[round {r}] ç›‘å¯Ÿå®˜ {j} å°è¯• {attempt + 1} å¤±è´¥: {e}")
                    logger.error(traceback.format_exc())
                    if attempt == max_retries - 1:
                        return {"text": out if 'out' in locals() else "N/A", "error": str(e)}
            return None

        with ThreadPoolExecutor(max_workers=num_auditors) as executor:
            audits = list(executor.map(execute_auditor, range(1, num_auditors + 1)))
        audits = [a for a in audits if a]
        last_audits = audits

        # ä¿å­˜æœ¬è½®åŸå§‹æ•°æ®
        round_data = {
            "round": r,
            "plans": plans,
            "audits": audits
        }
        with open(os.path.join(workspace_path, f"round_{r}_data.json"), "w", encoding="utf-8") as f:
            json.dump(round_data, f, ensure_ascii=False, indent=4)

        # 4. Leader Summary & Next Instructions
        logger.info(f"[round {r}] è®®é•¿æ­£åœ¨æ±‡æ€»æœ¬è½®ç»“æœ...")
        inputs = {
            "original_goal": decomposition['core_goal'],
            "previous_decomposition": decomposition,
            "plans": plans,
            "audits": audits,
            "previous_instructions": current_instructions,
            "user_interventions": user_interventions
        }
        
        final_summary = None
        for attempt in range(max_retries):
            logger.info(f"[round {r}] è®®é•¿æ­£åœ¨è°ƒç”¨æ¨¡å‹è¿›è¡Œæ±‡æ€» (å°è¯• {attempt + 1}/{max_retries})...")
            try:
                current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                out, search_res = stream_agent_output(leader_chain, {"inputs": json.dumps(inputs, ensure_ascii=False), "current_time": current_time_str}, "è®®é•¿", "Leader")
                if search_res:
                    all_search_references.append(search_res)
                
                cleaned = clean_json_string(out)
                if not cleaned:
                    raise ValueError("è®®é•¿æ€»ç»“è¾“å‡ºä¸ºç©ºæˆ–ä¸åŒ…å« JSON")
                    
                parsed = json.loads(cleaned)
                if "decomposition" not in parsed:
                    parsed["decomposition"] = decomposition
                else:
                    parsed["decomposition"]["core_goal"] = decomposition["core_goal"]
                
                summary_obj = schemas.LeaderSummary(**parsed)
                final_summary = summary_obj.dict()
                logger.info(f"[round {r}] è®®é•¿æ±‡æ€»æˆåŠŸ (å°è¯• {attempt + 1})")
                break
            except Exception as e:
                logger.warning(f"[round {r}] è®®é•¿æ±‡æ€»å°è¯• {attempt + 1} å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
                if attempt == max_retries - 1:
                    final_summary = {
                        "round": r,
                        "decomposition": decomposition,
                        "instructions": "ç»§ç»­ä¼˜åŒ–æ–¹æ¡ˆ",
                        "summary": {"consensus": ["æ— æ³•è¾¾æˆå…±è¯†"], "controversies": ["æ ¼å¼è§£æå¤±è´¥"]}
                    }

        history.append({
            "round": r,
            "plans": plans,
            "audits": audits,
            "summary": final_summary
        })

        # ä¿å­˜æœ¬è½®æ±‡æ€»åçš„ history
        with open(os.path.join(workspace_path, "history.json"), "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=4)

        # æ›´æ–°ä¸‹ä¸€è½®æŒ‡ä»¤
        current_instructions = f"æ ¸å¿ƒç›®æ ‡: {decomposition['core_goal']}\nä¸Šè½®æ€»ç»“: {final_summary['summary']}\nè®®é•¿æŒ‡ä»¤: {final_summary['instructions']}"

        # 5. æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        has_excellent = False
        excellent_plan_ids = []
        for audit in audits:
            if isinstance(audit, dict) and "reviews" in audit:
                for review in audit["reviews"]:
                    if review.get("rating") == "ä¼˜ç§€":
                        has_excellent = True
                        excellent_plan_ids.append(review.get("plan_id"))
        
        no_controversies = False
        controversies = []
        if final_summary and "summary" in final_summary:
            controversies = final_summary["summary"].get("controversies", [])
            if not controversies:
                no_controversies = True

        all_infeasible = True
        if not audits:
            all_infeasible = False
        else:
            for audit in audits:
                if isinstance(audit, dict) and "reviews" in audit:
                    for review in audit["reviews"]:
                        if review.get("rating") != "ä¸å¯è¡Œ":
                            all_infeasible = False
                            break
                if not all_infeasible: break

        if has_excellent and no_controversies:
            logger.info(f"[round {r}] åˆ¤å®šç»“è®ºï¼šè¾¾æˆå…±è¯†ã€‚ä¾æ®ï¼šå‘ç°ä¼˜ç§€æ–¹æ¡ˆ({excellent_plan_ids})ä¸”æ— æ ¸å¿ƒäº‰è®®ã€‚")
            break
        elif all_infeasible and len(audits) > 0:
            logger.warning(f"[round {r}] åˆ¤å®šç»“è®ºï¼šè®¨è®ºç»ˆæ­¢ã€‚ä¾æ®ï¼šæ‰€æœ‰æ–¹æ¡ˆå‡è¢«åˆ¤å®šä¸ºä¸å¯è¡Œã€‚")
            break
        elif r == max_rounds:
            logger.info(f"[round {r}] åˆ¤å®šç»“è®ºï¼šè¾¾åˆ°æœ€å¤§è½®æ•°ã€‚")
        else:
            logger.info(f"[round {r}] åˆ¤å®šç»“è®ºï¼šè¿›å…¥ä¸‹ä¸€è½®ã€‚")

    # 5. Final Reporting
    logger.info("[cycle] æŠ¥å‘Šè€…æ­£åœ¨ç”Ÿæˆæœ€ç»ˆ HTML æŠ¥å‘Š...")
    
    simplified_history = []
    for h in history:
        if h.get("type") == "user_intervention":
            simplified_history.append(h)
            continue
            
        simplified_history.append({
            "round": h["round"],
            "plans": [{"id": p.get("id"), "text": p.get("text")} for p in h.get("plans", [])],
            "audits": [{"auditor_id": a.get("auditor_id"), "reviews": a.get("reviews")} for a in h.get("audits", [])],
            "summary": h.get("summary")
        })

    # æ‰¾åˆ°æœ€åä¸€ä¸ªåŒ…å« summary çš„è®°å½•ä½œä¸ºæœ€ç»ˆæ€»ç»“
    last_summary = None
    for h in reversed(history):
        if "summary" in h:
            last_summary = h["summary"]
            break

    final_data = {
        "issue": issue_text,
        "decomposition": decomposition,
        "history": simplified_history,
        "final_summary": last_summary
    }
    
    # ä¿å­˜æœ€ç»ˆè¾“å…¥æ•°æ®
    with open(os.path.join(workspace_path, "final_session_data.json"), "w", encoding="utf-8") as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    
    # ä¿å­˜æœç´¢å‚è€ƒèµ„æ–™
    with open(os.path.join(workspace_path, "search_references.json"), "w", encoding="utf-8") as f:
        json.dump(all_search_references, f, ensure_ascii=False, indent=4)

    report_html = generate_report_from_workspace(workspace_path, model_config)

    return {
        "decomposition": decomposition,
        "history": history,
        "final": last_summary,
        "report_html": report_html
    }

def generate_report_from_workspace(workspace_path: str, model_config: Dict[str, Any]) -> str:
    """æ ¹æ®å·¥ä½œåŒºä¿å­˜çš„æ•°æ®é‡æ–°ç”ŸæˆæŠ¥å‘Šã€‚"""
    logger.info(f"[report] æ­£åœ¨ä»å·¥ä½œåŒº {workspace_path} é‡æ–°ç”ŸæˆæŠ¥å‘Š...")
    
    try:
        # åŠ è½½æ•°æ®
        with open(os.path.join(workspace_path, "final_session_data.json"), "r", encoding="utf-8") as f:
            final_data = json.load(f)
        
        # åŠ è½½æœç´¢å‚è€ƒèµ„æ–™ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸ºç©º
        all_search_references = []
        refs_path = os.path.join(workspace_path, "search_references.json")
        if os.path.exists(refs_path):
            with open(refs_path, "r", encoding="utf-8") as f:
                all_search_references = json.load(f)
            
        reporter_chain = make_reporter_chain(model_config)
        
        unique_refs = []
        seen_refs = set()
        for ref in all_search_references:
            if ref not in seen_refs:
                unique_refs.append(ref)
                seen_refs.add(ref)
        
        search_refs_text = "\n\n".join(unique_refs) if unique_refs else "æ— è”ç½‘æœç´¢å‚è€ƒèµ„æ–™ã€‚"
        if len(search_refs_text) > 15000:
            search_refs_text = search_refs_text[:15000] + "\n\n...(å†…å®¹è¿‡é•¿å·²æˆªæ–­)"

        max_retries = 3
        report_html = "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"
        
        for attempt in range(max_retries):
            try:
                logger.info(f"[report] æ­£åœ¨è°ƒç”¨æ¨¡å‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š (å°è¯• {attempt + 1}/{max_retries})...")
                report_html, _ = stream_agent_output(
                    reporter_chain, 
                    {
                        "final_data": json.dumps(final_data, ensure_ascii=False),
                        "search_references": search_refs_text
                    }, 
                    "æŠ¥å‘Šè€…", 
                    "Reporter",
                    event_type="final_report"
                )
                
                report_html = report_html.strip()
                if report_html.startswith("```html"):
                    report_html = report_html[7:]
                elif report_html.startswith("```"):
                    report_html = report_html[3:]
                if report_html.endswith("```"):
                    report_html = report_html[:-3]
                report_html = report_html.strip()
                
                send_web_event("final_report", content=report_html)
                
                # ä¿å­˜åˆ° Workspace
                filepath = os.path.join(workspace_path, "report.html")
                
                # å¦‚æœå·²å­˜åœ¨æ—§æŠ¥å‘Šï¼Œåˆ™é‡å‘½åå¤‡ä»½
                if os.path.exists(filepath):
                    old_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_path = os.path.join(workspace_path, f"report_old_{old_timestamp}.html")
                    try:
                        os.rename(filepath, backup_path)
                        logger.info(f"[report] å·²å°†æ—§æŠ¥å‘Šé‡å‘½åä¸º: {backup_path}")
                    except Exception as e:
                        logger.warning(f"[report] é‡å‘½åæ—§æŠ¥å‘Šå¤±è´¥: {e}")

                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(report_html)
                
                # åŒæ—¶ä¿ç•™ä¸€ä»½åˆ°å…¨å±€ reports ç›®å½•
                reports_dir = os.path.join(os.getcwd(), "reports")
                if not os.path.exists(reports_dir):
                    os.makedirs(reports_dir)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                legacy_filepath = os.path.join(reports_dir, f"report_{timestamp}.html")
                with open(legacy_filepath, "w", encoding="utf-8") as f:
                    f.write(report_html)
                
                logger.info(f"[report] æŠ¥å‘Šå·²ä¿å­˜è‡³ Workspace: {filepath}")
                return report_html
            except Exception as e:
                logger.warning(f"[report] æŠ¥å‘Šç”Ÿæˆå°è¯• {attempt + 1} å¤±è´¥: {e}")
                logger.error(traceback.format_exc())
        
        return report_html
        
    except Exception as e:
        logger.error(f"[report] ä»å·¥ä½œåŒºç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return "æŠ¥å‘Šç”Ÿæˆå¤±è´¥"

